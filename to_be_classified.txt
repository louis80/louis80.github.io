
################################################################################
 • Docker
- Not enough memory :
Switching cpu and mem to min allowed me to get docker restarted
Cleaned up containers with "docker ps -a"
Switching back: Docker now runs with max 2 cpu’s and 2048 memory settings

Remove all stopped containers :
docker system prune


# -*- coding: utf-8 -*-

import os
import psycopg2
import yaml
import pandas as pd
import requests
import json
from sqlalchemy import create_engine
import sys
from datetime import datetime
import time

import asyncio
from pyppeteer import launch
import re
from random import *


##############################################################################
####### CONNEXION A LA BDD #######

try:
    f = open('C:/Users/ljeanpierre/Documents/GitHub/synerciel.yml', 'r')
    conf = yaml.safe_load(f)
except:
    conf = yaml.load(os.getenv("PROJECT_CONFIG"))

def database_conn():
    return psycopg2.connect(host = conf["project-database"]["hostname"],
                            port = '5432',
                            database = conf["project-database"]["name"],
                            user = conf["project-database"]["user"],
                            password = conf["project-database"]["password"])

def get_data_from_database(req):
    conn = database_conn()
    cursor = conn.cursor()
    cursor.execute(req)
    record = cursor.fetchall()
    cursor.close()
    if (conn):
        conn.close()
    return record

##############################################################################
####### GET PROSPECTS #######

req_qualibat = """
SELECT base_sirene."siret", base_sirene."denominationUniteLegale"
FROM base_sirene
INNER JOIN qualibat
ON base_sirene.siret = qualibat.siret;
"""

req_qualifelec = """
SELECT base_sirene."siret", base_sirene."denominationUniteLegale"
FROM base_sirene
INNER JOIN qualifelec
ON base_sirene.siret = qualifelec.siret;
"""

### New request to not consider siret already scraped
req_qualibat = """
SELECT base_sirene."siret", base_sirene."denominationUniteLegale"
FROM base_sirene
INNER JOIN qualibat
ON base_sirene.siret = qualibat.siret
WHERE not exists (select siret from financial_overview where qualibat.siret= financial_overview.siret);
"""

req_qualifelec = """
SELECT base_sirene."siret", base_sirene."denominationUniteLegale"
FROM base_sirene
INNER JOIN qualifelec
ON base_sirene.siret = qualifelec.siret
WHERE not exists (select siret from financial_overview where qualifelec.siret= financial_overview.siret);
"""

qualibat = pd.DataFrame(get_data_from_database(req_qualibat) )
qualifelec =  pd.DataFrame(get_data_from_database(req_qualifelec) )
df_full = pd.concat([qualibat, qualifelec])
df_full.columns = ['siret','raison_sociale']

##############################################################################
####### SCRAP FUNCTION #######

def get_dates_from_array(arr):
    dates = []
    for i in arr:
        if re.search('[0-9]+', str(i)) is not None:
            dates.append(str(i).replace(' ', ''))

    return dates

def get_state_var(var):
    if (re.search('[0-9]+', str(var)) is not None) or (re.search('N/C', str(var)) is not None):
        return True
    else:
        return False

def parse_array_to_json(arr, dates):
    json = {}
    for i in range(len(arr)):
        if (re.search('[0-9]+', str(arr[i])) is None) and (re.search('N/C', str(arr[i])) is None):
            name_var = arr[i].replace(' ', '_').replace('d\'', '').replace('l\'', '').lower()
            if get_state_var(arr[i+1]) and get_state_var(arr[i+2]) and get_state_var(arr[i+3]):
                json[name_var] = {dates[2]+' ':arr[i+3], dates[1]:arr[i+2], dates[0]:arr[i+1]}
            else:
                json[name_var] = {}

    return json

def parse_state_to_json(arr):
    json = {}

    for x in arr :
        state = ''
        if re.search('<p class="ButtonSynthese green">(.*?)</p>', str(x)) is not None :
            state = 'favorable'
        elif re.search('<p class="ButtonSynthese yellow">(.*?)</p>', str(x)) is not None :
            state = 'Moyen'
        else:
            state = 'Défavorable'

        if  re.search('Rating societe', str(x)) is not None :
            json['rating_societe'] = state
        elif re.search('Equilibre Bilan', str(x)) is not None :
            json['equilibre_bilan'] = state
        elif re.search('Rentabilité', str(x)) is not None :
            json['rentabilite'] = state
    return json

def proxys():
    username = 'lum-customer-siapartners-zone-residential-session-'+str(random.randint(0,100))+'-country-fr'
    password = '4528ae05b7a9'
    port = 22225
    session_id = random.random()
    super_proxy_url = ('http://%s-session-%s:%s@zproxy.luminati.io:%d' %
        (username, session_id, password, port))
    return super_proxy_url

async def main(url='http://example.com', proxy=False):
    json = {}

    if proxy == False:
        browser = await launch()
    else:
        browser = await launch(args =[proxys()])

    page = await browser.newPage()
    await page.goto(url)

    dates = await page.evaluate('''() => {
    const tds = Array.from(document.querySelectorAll('#etat-financier table tr th'))
        return tds.map(td => td.innerHTML)
    }''')

    dates = get_dates_from_array(dates)

    data = await page.evaluate('''() => {
    const tds = Array.from(document.querySelectorAll('#etat-financier table tr td'))
        return tds.map(td => td.innerHTML)
    }''')

    json['etats_financiers'] = parse_array_to_json(data, dates)

    kpi = await page.evaluate('''() => {
    const tds = Array.from(document.querySelectorAll('.SyntheseAnafi__recap .lignesynthese'))
        return tds.map(td => td.innerHTML)
    }''')

    json['overview'] = parse_state_to_json(kpi)

    await page.close()
    await browser.close()

    return json

def get_url(siret, raison_sociale):
    siren = siret[0:9]
    raison_sociale = raison_sociale.replace(' ', '-').lower()
    return 'https://www.societe.com/analyse-financiere/'+raison_sociale+'-'+siren+'.html'

##############################################################################
####### EXPORT DATA #######

def sent_reviews_to_db(siret, json, state='append'):
    engine = create_engine('postgresql://'+ conf["project-database"]["user"] + ':' + conf["project-database"]["password"] + '@' +
                     conf["project-database"]["hostname"] +':' + '5432/' + conf["project-database"]["name"])

    df_financial_overview = pd.DataFrame(columns=['siret', 'equilibre_bilan', 'rating_societe', 'rentabilite'])
    df_financial_state = {'siret': str(siret)}

    if json == 'error':
        print('sending error to db' )
        df_financial_overview = df_financial_overview.append({'siret': str(siret), 'equilibre_bilan':'', 'rating_societe':'', 'rentabilite':'', 'time_extract':datetime.now()}, ignore_index=True)
    else:
        ### financial_overview ###
        df_financial_overview = df_financial_overview.append({'siret': str(siret), 'equilibre_bilan':json['overview']['equilibre_bilan'], 'rating_societe':json['overview']['rating_societe'], 'rentabilite':json['overview']['rentabilite'], 'time_extract':datetime.now()}, ignore_index=True)

        ### financial_state ###
        for i in json['etats_financiers']:
            df_financial_state[i] = json['etats_financiers'][i]
        df_financial_state['time_extract'] = datetime.now()
        df_financial_state = pd.DataFrame(df_financial_state).reset_index().rename({'index': 'year'}, axis='columns')
        df_financial_state.applymap(str).to_sql('financial_state',
                    con=engine, if_exists=state, index=False)

    df_financial_overview.applymap(str).to_sql('financial_overview',
                con=engine, if_exists=state, index=False)


def main_(df_full, beg, end, time_sleep=1, proxy=False):
    print('')
    count_error = 0
    cumulative_error = 0
    start=datetime.now()

    for i in range(beg, end):

        if df_full.iat[i, 1] != 'nan' :
            url = get_url(siret= df_full.iat[i, 0], raison_sociale=df_full.iat[i, 1])
            start_query = datetime.now()
            try:
                json = asyncio.get_event_loop().run_until_complete(main(url, proxy=proxy))
                sent_reviews_to_db(str(df_full.iat[i, 0]), json, state='append')
                print(i, ' | total time : ', datetime.now()-start, ' | time query : ', datetime.now()-start_query, ' | nbre_error : ', count_error)
                cumulative_error = 0
            except:
                cumulative_error += 1
                count_error += 1
                print('\n error : ', url,'\n count error : ', count_error, ' | cumulative_error : ',cumulative_error)
                sent_reviews_to_db(str(df_full.iat[i, 0]), 'error')
                ###
                if cumulative_error > 30:
                    break
                ###
            time.sleep(time_sleep)
        else:
            print(i, ' | total time : ', datetime.now()-start, ' | no raison sociale ')
            sent_reviews_to_db(str(df_full.iat[i, 0]), 'error')

    print('Job done ! ', (1 - (count_error/(end-beg)))*100, ' % of success')


beg = 0
end = 1000
print('beg : ', beg)
print('end : ', end)

main_(df_full, beg, end)
